---
---

@inproceedings{realmdreamer,
  author = {Shriram*, Jaidev and Trevithick*, Alex and Liu, Lingjie, and Ramamoorthi, Ravi},
  title  = {RealmDreamer: Text-Driven 3D Scene Generation with Inpainting and Depth Diffusion},
  year   = {2025},
  booktitle = {International Conference on 3D Vision (3DV)},
  url   = {https://realmdreamer.github.io},
  abstract = {
     We introduce RealmDreamer, a technique for generation of general forward-facing 3D scenes from text descriptions. Our technique optimizes a 3D Gaussian Splatting representation to match complex text prompts. We initialize these splats by utilizing the state-of-the-art text-to-image generators, lifting their samples into 3D, and computing the occlusion volume. We then optimize this representation across multiple views as a 3D inpainting task with image-conditional diffusion models. To learn correct geometric structure, we incorporate a depth diffusion model by conditioning on the samples from the inpainting model, giving rich geometric structure. Finally, we finetune the model using sharpened samples from image generators. Notably, our technique does not require training on any scene-specific dataset and can synthesize a variety of high-quality 3D scenes in different styles, consisting of multiple objects. Its generality additionally allows 3D synthesis from a single image.
  },
  arxiv={2404.07199},
  website={https://realmdreamer.github.io},
  preview={realmdreamer.gif},
  % press = {Radiance Fields, https://radiancefields.com/realmdreamers-generative-scenes},
}

@inproceedings{10.1145/3586182.3625118,
  author = {Shriram, Jaidev and Pradeep Kumar Sreekala, Sanjayan},
  title = {ZINify: Transforming Research Papers into Engaging Zines with Large Language Models},
  year = {2023},
  isbn = {9798400700965},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3586182.3625118},
  doi = {10.1145/3586182.3625118},
  booktitle = {Adjunct Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
  articleno = {117},
  abstract = {
Research papers are a vital building block for scientific discussion. While these papers follow effective structures for the relevant community, they are unable to cater to novice readers and express otherwise creative ideas in creative mediums. To this end, we propose ZINify, the first approach to automatically transform research papers into engaging zines using large language models (LLM) and text-to-image generators. Following zine‚Äôs long history of supporting independent, creative expression, we propose a technique that can work with authors to build more engaging, marketable, and unconventional content that is based on their research. We believe that our work will help make research more engaging and accessible to all while helping papers stand out in crowded online venues.
  },
  numpages = {3},
  location = {San Francisco, CA, USA},
  series = {UIST '23 Adjunct},
  website={https://jaidevshriram.com/zinify-uist/},
  text={üèÖ Honourable Mention (People‚Äôs Choice)},
  preview={zinify.png},
}

@inproceedings{shriram2021much,
  abbr={SMM},
  title={How Much do Lyrics Matter? Analysing Lyrical Simplicity Preferences for Individuals At Risk of Depression},
  author={Shriram, Jaidev and Paruchuri, Sreeharsha and Alluri, Vinoo},
  booktitle={Speech, Music and Mind 2021, Satellite Workshop of INTERSPEECH},
  pdf={https://www.isca-speech.org/archive/pdfs/smm_2021/shriram21_smm.pdf},
  abstract={Music affects and in some cases reflects one‚Äôs emotional
  state. Key to this influence is lyrics and their meaning in conjunction with the acoustic properties of the track. Recent work
  has focused on analysing these acoustic properties and showing that individuals prone to depression primarily consume low
  valence and low energy music. However, no studies yet have
  explored lyrical content preferences in relation to online music
  consumption of such individuals. In the current study, we examine lyrical simplicity, measured as the Compressibility and Ab-
  solute Information Content of the text, associated with preferences of individuals at risk for depression. Using the six-month
  listening history of 541 Last.fm users, we compare lyrical simplicity trends for users grouped as being at risk (At-Risk) of de-
  pression from those that are not (No-Risk). Our findings reveal
  that At-Risk individuals prefer songs with greater information
  content (lower Compressibility) on average, especially for songs
  characterised as Sad. Furthermore, we found that At-Risk individuals also have greater variability of Absolute Information
  Content across their listening history. We discuss the results
  in light of existing socio-psychological lab-based research on
  music habits associated with depression and their relevance to
  naturally occurring online music listening behaviour.},
  arxiv={2109.07227},
  year={2021}
}

@inproceedings{shriram2022ismir,
  abbr={ISMIR},
  title={Sonus Texere! Automated Dense Soundtrack Construction for Books using Movie Adaptations},
  author={Shriram, Jaidev and Tapaswi, Makarand and Alluri, Vinoo},
  booktitle={International Society for Music Information Retrieval (ISMIR)},
  abstract={Reading, much like music listening, is an immersive experience that transports readers while taking them on an
  emotional journey. Listening to complementary music has
  the potential to amplify the reading experience, especially
  when the music is stylistically cohesive and emotionally
  relevant. In this paper, we propose the first fully automatic
  method to build a dense soundtrack for books, which can
  play high-quality instrumental music for the entirety of the
  reading duration. Our work employs a unique text processing and music weaving pipeline that determines the
  context and emotional composition of scenes in a chapter. This allows our method to identify and play relevant
  excerpts from the soundtrack of the book‚Äôs movie adaptation. By relying on the movie composer‚Äôs
  craftsmanship, our book soundtracks include expert-made motifs and
  other scene-specific musical characteristics. We validate
  the design decisions of our approach through a perceptual
  study. Our readers note that the book soundtrack greatly
  enhanced their reading experience, due to high immersiveness granted via uninterrupted and style-consistent music,
  and a heightened emotional state attained via high precision emotion and scene context recognition.},
  year={2022},
  selected={true},
  preview={ISMIR_Thumbnail.png},
  url={https://auto-book-soundtrack.github.io},
  arxiv={2212.01033},
  website={https://auto-book-soundtrack.github.io},
  text={üèÖ Brave New Idea Award!},
  press={Times of India, https://timesofindia.indiatimes.com/city/hyderabad/books-get-background-music-courtesy-iiit-h/articleshow/96670016.cms; The Hindu Businessline, https://www.thehindubusinessline.com/news/music-to-match-the-mood-of-the-book-you-are-reading/article66274355.ece; IIIT-H Blogs, https://blogs.iiit.ac.in/soundtrack-for-books/; Eenadu (Telugu Newspaper), https://epaper.eenadu.net/Home/Index?date=16%2F12%2F2022&eid=27&pid=2028914; Good E Reader, https://goodereader.com/blog/e-book-news/indian-trio-devise-algorithm-to-add-suitable-music-to-match-different-moods-in-an-e-book; Newstap, https://www.newstap.in/education/iiit-h-creation-plays-suitable-bgm-while-reading-books-wins-award-1452731}
}

@inproceedings{singh2022iros,
  abbr={IROS},
  title={IndoLayout: Leveraging Attention for Extended Indoor Layout Estimation from an RGB Image},
  author={Singh, Shantanu and Shriram, Jaidev and Kulkarni, Shaantanu and Bhomwick, Brojeshwar and Krishna, K. Madhava},
  booktitle={International Conference on Intelligent Robots and Systems (IROS)},
  abstract={In this work, we propose IndoLayout, a novel realtime approach for generating high-quality occupancy maps
  from an RGB image for indoor scenes. Such occupancy maps
  are often crucial for path-planning and mapping in indoor environments but are often built using only information contained in
  the ego view. In contrast, our approach also predicts occupancy
  values beyond immediately visible regions from just a monocular image, leveraging learnt priors from indoor scenes. Hence,
  our proposed network can produce a hallucinated, amodal scene
  layout that includes areas occluded in the RGB image, such
  as a navigable floor behind a desk. Specifically, we propose
  a novel architecture that uses self-attention and adversarial
  learning to vastly improve the quality of the predicted layout.
  We evaluate our model on several photorealistic indoor datasets
  and outperform previous relevant work on all metrics that
  measure layout quality, including newly adopted ones. Finally,
  we demonstrate the effectiveness of our method by showing
  significant improvements on the PointNav task over similar
  approaches using IndoLayout.},
  preview={iros.png},
  website={https://ieeexplore.ieee.org/document/9982106},
  year={2022}
}
