@inproceedings{shriram2021much,
  title={How Much do Lyrics Matter? Analysing Lyrical Simplicity Preferences for Individuals At Risk of Depression},
  author={Shriram, Jaidev and Paruchuri, Sreeharsha and Alluri, Vinoo},
  booktitle={Speech, Music and Mind 2021, Satellite Workshop of INTERSPEECH},
  pdf={Jaidev_SMM_2022.pdf},
  abstract={Music affects and in some cases reflects one’s emotional
  state. Key to this influence is lyrics and their meaning in conjunction with the acoustic properties of the track. Recent work
  has focused on analysing these acoustic properties and showing that individuals prone to depression primarily consume low
  valence and low energy music. However, no studies yet have
  explored lyrical content preferences in relation to online music
  consumption of such individuals. In the current study, we examine lyrical simplicity, measured as the Compressibility and Ab-
  solute Information Content of the text, associated with preferences of individuals at risk for depression. Using the six-month
  listening history of 541 Last.fm users, we compare lyrical simplicity trends for users grouped as being at risk (At-Risk) of de-
  pression from those that are not (No-Risk). Our findings reveal
  that At-Risk individuals prefer songs with greater information
  content (lower Compressibility) on average, especially for songs
  characterised as Sad. Furthermore, we found that At-Risk individuals also have greater variability of Absolute Information
  Content across their listening history. We discuss the results
  in light of existing socio-psychological lab-based research on
  music habits associated with depression and their relevance to
  naturally occurring online music listening behaviour.},
  arxiv={2109.07227},
  year={2021}
}

@inproceedings{shriram2022ismir,
  title={(Upcoming) Sonus Texere! Automated Dense Soundtrack Construction for Books using Movie Adaptations},
  author={Shriram, Jaidev and Tapaswi, Makarand and Alluri, Vinoo},
  booktitle={International Society for Music Information Retrieval (ISMIR)},
  abstract={Reading, much like music listening, is an immersive experience that transports readers while taking them on an
  emotional journey. Listening to complementary music has
  the potential to amplify the reading experience, especially
  when the music is stylistically cohesive and emotionally
  relevant. In this paper, we propose the first fully automatic
  method to build a dense soundtrack for books, which can
  play high-quality instrumental music for the entirety of the
  reading duration. Our work employs a unique text processing and music weaving pipeline that determines the
  context and emotional composition of scenes in a chapter. This allows our method to identify and play relevant
  excerpts from the soundtrack of the book’s movie adaptation. By relying on the movie composer’s
  craftsmanship, our book soundtracks include expert-made motifs and
  other scene-specific musical characteristics. We validate
  the design decisions of our approach through a perceptual
  study. Our readers note that the book soundtrack greatly
  enhanced their reading experience, due to high immersiveness granted via uninterrupted and style-consistent music,
  and a heightened emotional state attained via high precision emotion and scene context recognition.},
  year={2022}
}

@inproceedings{singh2022iros,
  title={(Upcoming) IndoLayout: Leveraging Attention for Extended Indoor Layout Estimation from an RGB Image},
  author={Singh, Shantanu and Shriram, Jaidev and Kulkarni, Shaantanu and Bhomwick, Brojeshwar and Krishna, K. Madhava},
  booktitle={International Conference on Intelligent Robots and Systems (IROS)},
  abstract={In this work, we propose IndoLayout, a novel realtime approach for generating high-quality occupancy maps
  from an RGB image for indoor scenes. Such occupancy maps
  are often crucial for path-planning and mapping in indoor environments but are often built using only information contained in
  the ego view. In contrast, our approach also predicts occupancy
  values beyond immediately visible regions from just a monocular image, leveraging learnt priors from indoor scenes. Hence,
  our proposed network can produce a hallucinated, amodal scene
  layout that includes areas occluded in the RGB image, such
  as a navigable floor behind a desk. Specifically, we propose
  a novel architecture that uses self-attention and adversarial
  learning to vastly improve the quality of the predicted layout.
  We evaluate our model on several photorealistic indoor datasets
  and outperform previous relevant work on all metrics that
  measure layout quality, including newly adopted ones. Finally,
  we demonstrate the effectiveness of our method by showing
  significant improvements on the PointNav task over similar
  approaches using IndoLayout.},
  year={2022}
}
